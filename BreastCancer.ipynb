{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP2Mp8gyaSGG9Rk2/cHL91v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/analeticiagarcez/Breast_cancer_segmentation_and_classification/blob/features/BreastCancer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://cloud.andrelab.icmc.usp.br/s/xX2SbG4cLiNCPMA/download/archive.zip\n",
        "!unzip archive.zip"
      ],
      "metadata": {
        "id": "gRTTo5HVsyDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tratamento das saídas\n",
        "\n",
        "EXPLICAÇÃO"
      ],
      "metadata": {
        "id": "7Zqg1IL-vBi3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "path_dataset = '/content/Dataset_BUSI_with_GT/'\n",
        "classes = os.listdir(path_dataset)\n",
        "\n",
        "# Itera sobre as classes\n",
        "for c in classes:\n",
        "  # Monta o path para a pasta da classe\n",
        "  path_class = os.path.join(path_dataset, c)\n",
        "  # Pega o nome dos arquivos\n",
        "  nome_imagens = os.listdir(path_class)\n",
        "  for nome_imagem in nome_imagens:\n",
        "    if 'mask_' in nome_imagem:\n",
        "      # Escrevo o nome da nova imagem\n",
        "      nome_imagem_original = re.sub('_[0-9]+', '', nome_imagem)\n",
        "      # Cria o path das máscaras\n",
        "      path_imagem_original =  os.path.join(path_class, nome_imagem_original)\n",
        "      path_imagem_atual =  os.path.join(path_class, nome_imagem)\n",
        "      # Abre as imagens\n",
        "      img_original = cv2.imread(path_imagem_original)\n",
        "      img_atual = cv2.imread(path_imagem_atual)\n",
        "      img_somada = cv2.add(img_original, img_atual)\n",
        "      # Sobrescreve o arquivo com as imagens fundidas\n",
        "      cv2.imwrite(path_imagem_original, img_somada)"
      ],
      "metadata": {
        "id": "iCOA7-douJ2q"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Leitura das imagens"
      ],
      "metadata": {
        "id": "ZQ1Kkvk142Ta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "class DadosImagens(Dataset):\n",
        "  def __init__(self, path, image_size):\n",
        "    self.files_path = path\n",
        "    self.imagens = []\n",
        "    self.masks = []\n",
        "    self.image_class = []\n",
        "    self.__transform(image_size)\n",
        "    #Lista as classes dos dados\n",
        "    classes = os.listdir(self.files_path)\n",
        "    # Itera sobre as classes\n",
        "    for c in classes:\n",
        "      # Monta o path para a pasta da classe\n",
        "      path_class = os.path.join(path_dataset, c)\n",
        "      # Pega o nome dos arquivos\n",
        "      nome_imagens = os.listdir(path_class)\n",
        "      for nome_imagem in nome_imagens:\n",
        "        if 'mask' in nome_imagem:\n",
        "          continue\n",
        "        # Monta o caminho para a imagem de entrada e a mácara\n",
        "        path_imagem = os.path.join(path_class, nome_imagem)\n",
        "        path_mask = path_imagem.replace('.', '_mask.')\n",
        "        # Faz a leitura da máscara\n",
        "        imagem = Image.open(path_imagem)\n",
        "        mask =  Image.open(path_mask)\n",
        "        # Salva as imagens na lista\n",
        "        self.imagens.append(imagem)\n",
        "        self.masks.append(mask)\n",
        "        self.image_class.append(c)\n",
        "\n",
        "  def __transform(self, image_size):\n",
        "    # Inicializa o transormador dos dados\n",
        "    self.transform = transforms.Compose([\n",
        "        transforms.Resize(image_size),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.imagens)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    # Pega as imagens no índice\n",
        "    imagem = self.imagens[idx]\n",
        "    mask = self.masks[idx]\n",
        "    classe = self.image_class[idx]\n",
        "    # Transforma as imagens\n",
        "    imagem = self.transform(imagem)\n",
        "    mask = self.transform(mask)\n",
        "    # Retorna os dados das imagens\n",
        "    return {'img': imagem, 'mask': mask, 'label': classe}\n",
        "\n",
        "dados = DadosImagens(path_dataset, (256,256))"
      ],
      "metadata": {
        "id": "Et2qU9XG41iV"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "paeGDz0CrNQ0",
        "outputId": "e9a23ff4-f3f4-4875-befe-707780d0e48d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-9f2f50380d33>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet',\n\u001b[0m\u001b[1;32m      4\u001b[0m     in_channels=1, out_channels=1, init_features=32, pretrained=True)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/hub.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(repo_or_dir, model, source, trust_repo, force_reload, verbose, skip_validation, *args, **kwargs)\u001b[0m\n\u001b[1;32m    556\u001b[0m                                            verbose=verbose, skip_validation=skip_validation)\n\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_or_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/hub.py\u001b[0m in \u001b[0;36m_load_local\u001b[0;34m(hubconf_dir, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mentry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_entry_from_hubconf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhub_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 587\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master/hubconf.py\u001b[0m in \u001b[0;36munet\u001b[0;34m(pretrained, **kwargs)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://github.com/mateuszbuda/brain-segmentation-pytorch/releases/download/v1.0/unet-e012d006.pt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict_from_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   2039\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2041\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   2042\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   2043\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for UNet:\n\tsize mismatch for encoder1.enc1conv1.weight: copying a param with shape torch.Size([32, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 1, 3, 3])."
          ]
        }
      ],
      "source": [
        "import torchvision.models\n",
        "\n",
        "model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet',\n",
        "    in_channels=1, out_channels=1, init_features=32, pretrained=True)"
      ]
    }
  ]
}